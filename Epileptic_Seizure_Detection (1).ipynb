{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jteO7YI2qgaX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Conv1D, BatchNormalization, Dropout, Flatten, Dense, Input,\n",
        "                                    LSTM, Bidirectional, MultiHeadAttention, LayerNormalization, MaxPooling1D)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zZRUyNiqudS",
        "outputId": "0f16223a-bd26-4249-ed90-2f3508032167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0    0\n",
            "X1            0\n",
            "X2            0\n",
            "X3            0\n",
            "X4            0\n",
            "             ..\n",
            "X175          0\n",
            "X176          0\n",
            "X177          0\n",
            "X178          0\n",
            "y             0\n",
            "Length: 180, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "print(data.isnull().sum())  # Check for missing values\n",
        "data = data.dropna()\n",
        "X = data.iloc[:, 1:-1].values\n",
        "y = data.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Sm5nbvxvq-zT"
      },
      "outputs": [],
      "source": [
        "# Preprocess labels\n",
        "y = np.where(y == 1, 1, 0)\n",
        "y = to_categorical(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "45X6-WeVrFhO"
      },
      "outputs": [],
      "source": [
        "# Normalize and reshape\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l1neWt8YrLNt"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GzypndRirRXn"
      },
      "outputs": [],
      "source": [
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y.argmax(axis=1)), y=y.argmax(axis=1))\n",
        "class_weight_dict = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5k8vqC1KrUh2"
      },
      "outputs": [],
      "source": [
        "# Define Transformer Encoder Block\n",
        "def transformer_block(x, num_heads, key_dim, ff_dim=256):\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
        "    ffn_output = Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ffn_output = Dense(x.shape[-1])(ffn_output)\n",
        "    ffn_output = LayerNormalization(epsilon=1e-6)(attn_output + ffn_output)\n",
        "    return ffn_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "twHnG_s3rYFE"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(filters=128, kernel_size=5, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = transformer_block(x, num_heads=4, key_dim=64, ff_dim=256)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "output_layer = Dense(2, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9PocwIUjriGk"
      },
      "outputs": [],
      "source": [
        "# Compile Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WneE82gArmnU"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGpqumvUrtju",
        "outputId": "cfbf5425-10ac-42cf-da67-cdb29175758e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 135ms/step - accuracy: 0.9326 - loss: 2.4006 - val_accuracy: 0.9148 - val_loss: 0.6749 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 133ms/step - accuracy: 0.9505 - loss: 0.5201 - val_accuracy: 0.9804 - val_loss: 0.3080 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 137ms/step - accuracy: 0.9635 - loss: 0.2985 - val_accuracy: 0.9887 - val_loss: 0.1625 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 132ms/step - accuracy: 0.9779 - loss: 0.1771 - val_accuracy: 0.9826 - val_loss: 0.1415 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 132ms/step - accuracy: 0.9803 - loss: 0.1331 - val_accuracy: 0.9843 - val_loss: 0.1138 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - accuracy: 0.9815 - loss: 0.1194 - val_accuracy: 0.9343 - val_loss: 0.2098 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 132ms/step - accuracy: 0.9835 - loss: 0.0909 - val_accuracy: 0.9835 - val_loss: 0.0941 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 129ms/step - accuracy: 0.9799 - loss: 0.1071 - val_accuracy: 0.9900 - val_loss: 0.0756 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 129ms/step - accuracy: 0.9871 - loss: 0.0789 - val_accuracy: 0.9870 - val_loss: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 132ms/step - accuracy: 0.9908 - loss: 0.0591 - val_accuracy: 0.9878 - val_loss: 0.0876 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 130ms/step - accuracy: 0.9867 - loss: 0.0737 - val_accuracy: 0.9626 - val_loss: 0.1485 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 131ms/step - accuracy: 0.9867 - loss: 0.0832 - val_accuracy: 0.9848 - val_loss: 0.0809 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 130ms/step - accuracy: 0.9880 - loss: 0.0635 - val_accuracy: 0.9909 - val_loss: 0.0529 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 130ms/step - accuracy: 0.9928 - loss: 0.0421 - val_accuracy: 0.9809 - val_loss: 0.0865 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 142ms/step - accuracy: 0.9886 - loss: 0.0714 - val_accuracy: 0.9926 - val_loss: 0.0444 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 133ms/step - accuracy: 0.9911 - loss: 0.0543 - val_accuracy: 0.9926 - val_loss: 0.0580 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 133ms/step - accuracy: 0.9937 - loss: 0.0448 - val_accuracy: 0.9861 - val_loss: 0.0638 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 132ms/step - accuracy: 0.9857 - loss: 0.0854 - val_accuracy: 0.9909 - val_loss: 0.0513 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 136ms/step - accuracy: 0.9926 - loss: 0.0474 - val_accuracy: 0.9935 - val_loss: 0.0440 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 136ms/step - accuracy: 0.9916 - loss: 0.0428 - val_accuracy: 0.9600 - val_loss: 0.1821 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 132ms/step - accuracy: 0.9887 - loss: 0.0642 - val_accuracy: 0.9696 - val_loss: 0.1416 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 134ms/step - accuracy: 0.9919 - loss: 0.0402 - val_accuracy: 0.8974 - val_loss: 0.4256 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 143ms/step - accuracy: 0.9901 - loss: 0.0578 - val_accuracy: 0.9957 - val_loss: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 149ms/step - accuracy: 0.9947 - loss: 0.0255 - val_accuracy: 0.9917 - val_loss: 0.0665 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 147ms/step - accuracy: 0.9953 - loss: 0.0355 - val_accuracy: 0.9952 - val_loss: 0.0292 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 143ms/step - accuracy: 0.9959 - loss: 0.0238 - val_accuracy: 0.9939 - val_loss: 0.0427 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 153ms/step - accuracy: 0.9944 - loss: 0.0364 - val_accuracy: 0.9913 - val_loss: 0.0425 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 147ms/step - accuracy: 0.9967 - loss: 0.0256 - val_accuracy: 0.9417 - val_loss: 0.3174 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 151ms/step - accuracy: 0.9911 - loss: 0.0535 - val_accuracy: 0.9922 - val_loss: 0.0499 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 147ms/step - accuracy: 0.9932 - loss: 0.0451 - val_accuracy: 0.9961 - val_loss: 0.0343 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 137ms/step - accuracy: 0.9958 - loss: 0.0238 - val_accuracy: 0.9983 - val_loss: 0.0143 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 134ms/step - accuracy: 0.9987 - loss: 0.0118 - val_accuracy: 0.9978 - val_loss: 0.0151 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 138ms/step - accuracy: 0.9990 - loss: 0.0092 - val_accuracy: 0.9965 - val_loss: 0.0187 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 132ms/step - accuracy: 0.9989 - loss: 0.0086 - val_accuracy: 0.9970 - val_loss: 0.0173 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 137ms/step - accuracy: 0.9995 - loss: 0.0077 - val_accuracy: 0.9974 - val_loss: 0.0143 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 139ms/step - accuracy: 0.9992 - loss: 0.0066 - val_accuracy: 0.9952 - val_loss: 0.0199 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 135ms/step - accuracy: 0.9991 - loss: 0.0082 - val_accuracy: 0.9978 - val_loss: 0.0125 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 137ms/step - accuracy: 0.9992 - loss: 0.0078 - val_accuracy: 0.9965 - val_loss: 0.0157 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 140ms/step - accuracy: 0.9993 - loss: 0.0073 - val_accuracy: 0.9970 - val_loss: 0.0150 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 138ms/step - accuracy: 0.9993 - loss: 0.0063 - val_accuracy: 0.9970 - val_loss: 0.0154 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9939 - val_loss: 0.0289 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 140ms/step - accuracy: 0.9982 - loss: 0.0107 - val_accuracy: 0.9974 - val_loss: 0.0129 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 138ms/step - accuracy: 0.9997 - loss: 0.0037 - val_accuracy: 0.9983 - val_loss: 0.0127 - learning_rate: 1.2500e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 146ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 0.9935 - val_loss: 0.0318 - learning_rate: 1.2500e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 140ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.9896 - val_loss: 0.0350 - learning_rate: 1.2500e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 141ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.9970 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 142ms/step - accuracy: 0.9992 - loss: 0.0061 - val_accuracy: 0.9974 - val_loss: 0.0099 - learning_rate: 1.2500e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 138ms/step - accuracy: 0.9992 - loss: 0.0043 - val_accuracy: 0.9978 - val_loss: 0.0120 - learning_rate: 1.2500e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9983 - val_loss: 0.0118 - learning_rate: 1.2500e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 142ms/step - accuracy: 0.9998 - loss: 0.0029 - val_accuracy: 0.9983 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7930a823f150>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Train Model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32,\n",
        "          class_weight=class_weight_dict, callbacks=[early_stopping, lr_scheduler], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dA8FbPoOr5q-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc012f4-d286-4193-866c-030432d70461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step\n",
            "Test Accuracy: 99.74%\n",
            "Precision: 0.99\n",
            "Recall: 1.00\n",
            "F1-Score: 0.99\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "y_true = y_test.argmax(axis=1)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred):.2f}\")\n",
        "print(f\"F1-Score: {f1_score(y_true, y_pred):.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}