{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jteO7YI2qgaX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Conv1D, BatchNormalization, Dropout, Flatten, Dense, Input,\n",
        "                                    LSTM, Bidirectional, MultiHeadAttention, LayerNormalization, MaxPooling1D)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zZRUyNiqudS",
        "outputId": "6f1b9fdd-6900-48d9-d932-16f0d1946ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unnamed: 0    0\n",
            "X1            0\n",
            "X2            0\n",
            "X3            0\n",
            "X4            0\n",
            "             ..\n",
            "X175          0\n",
            "X176          0\n",
            "X177          0\n",
            "X178          0\n",
            "y             0\n",
            "Length: 180, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "print(data.isnull().sum())  # Check for missing values\n",
        "data = data.dropna()\n",
        "X = data.iloc[:, 1:-1].values\n",
        "y = data.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm5nbvxvq-zT"
      },
      "outputs": [],
      "source": [
        "# Preprocess labels\n",
        "y = np.where(y == 1, 1, 0)\n",
        "y = to_categorical(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45X6-WeVrFhO"
      },
      "outputs": [],
      "source": [
        "# Normalize and reshape\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1neWt8YrLNt"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzypndRirRXn"
      },
      "outputs": [],
      "source": [
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y.argmax(axis=1)), y=y.argmax(axis=1))\n",
        "class_weight_dict = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k8vqC1KrUh2"
      },
      "outputs": [],
      "source": [
        "# Define Transformer Encoder Block\n",
        "def transformer_block(x, num_heads, key_dim, ff_dim=256):\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
        "    ffn_output = Dense(ff_dim, activation='relu')(attn_output)\n",
        "    ffn_output = Dense(x.shape[-1])(ffn_output)\n",
        "    ffn_output = LayerNormalization(epsilon=1e-6)(attn_output + ffn_output)\n",
        "    return ffn_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twHnG_s3rYFE"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Conv1D(filters=128, kernel_size=5, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D(pool_size=2)(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = transformer_block(x, num_heads=4, key_dim=64, ff_dim=256)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
        "output_layer = Dense(2, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PocwIUjriGk"
      },
      "outputs": [],
      "source": [
        "# Compile Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WneE82gArmnU"
      },
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGpqumvUrtju",
        "outputId": "1a8500a9-82c3-4c2b-af94-42528aeb8e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 211ms/step - accuracy: 0.9149 - loss: 2.4671 - val_accuracy: 0.9574 - val_loss: 0.6186 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 203ms/step - accuracy: 0.9667 - loss: 0.5131 - val_accuracy: 0.9770 - val_loss: 0.3563 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 204ms/step - accuracy: 0.9640 - loss: 0.3178 - val_accuracy: 0.9835 - val_loss: 0.2340 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 204ms/step - accuracy: 0.9797 - loss: 0.1999 - val_accuracy: 0.9874 - val_loss: 0.1400 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 199ms/step - accuracy: 0.9826 - loss: 0.1350 - val_accuracy: 0.9883 - val_loss: 0.1166 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 203ms/step - accuracy: 0.9830 - loss: 0.1196 - val_accuracy: 0.9857 - val_loss: 0.1188 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 201ms/step - accuracy: 0.9842 - loss: 0.0954 - val_accuracy: 0.9757 - val_loss: 0.1531 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 196ms/step - accuracy: 0.9876 - loss: 0.1077 - val_accuracy: 0.9878 - val_loss: 0.0847 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 200ms/step - accuracy: 0.9859 - loss: 0.0855 - val_accuracy: 0.9878 - val_loss: 0.0617 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 203ms/step - accuracy: 0.9859 - loss: 0.0805 - val_accuracy: 0.9861 - val_loss: 0.0881 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 197ms/step - accuracy: 0.9823 - loss: 0.0925 - val_accuracy: 0.9848 - val_loss: 0.0854 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 201ms/step - accuracy: 0.9889 - loss: 0.0723 - val_accuracy: 0.9917 - val_loss: 0.0545 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 198ms/step - accuracy: 0.9874 - loss: 0.0635 - val_accuracy: 0.9835 - val_loss: 0.0850 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 201ms/step - accuracy: 0.9893 - loss: 0.0663 - val_accuracy: 0.9930 - val_loss: 0.0586 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 201ms/step - accuracy: 0.9928 - loss: 0.0508 - val_accuracy: 0.9883 - val_loss: 0.0889 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 201ms/step - accuracy: 0.9931 - loss: 0.0573 - val_accuracy: 0.9896 - val_loss: 0.0797 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 195ms/step - accuracy: 0.9898 - loss: 0.0565 - val_accuracy: 0.9939 - val_loss: 0.0528 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 199ms/step - accuracy: 0.9914 - loss: 0.0476 - val_accuracy: 0.9883 - val_loss: 0.0649 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 195ms/step - accuracy: 0.9934 - loss: 0.0400 - val_accuracy: 0.9900 - val_loss: 0.0804 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 196ms/step - accuracy: 0.9897 - loss: 0.0687 - val_accuracy: 0.9922 - val_loss: 0.0484 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 202ms/step - accuracy: 0.9915 - loss: 0.0654 - val_accuracy: 0.9926 - val_loss: 0.0648 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 202ms/step - accuracy: 0.9913 - loss: 0.0649 - val_accuracy: 0.9826 - val_loss: 0.0884 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 205ms/step - accuracy: 0.9921 - loss: 0.0480 - val_accuracy: 0.9891 - val_loss: 0.0572 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m128/288\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.9924 - loss: 0.0380"
          ]
        }
      ],
      "source": [
        "# Train Model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32,\n",
        "          class_weight=class_weight_dict, callbacks=[early_stopping, lr_scheduler], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA8FbPoOr5q-"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "y_true = y_test.argmax(axis=1)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision_score(y_true, y_pred):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_true, y_pred):.2f}\")\n",
        "print(f\"F1-Score: {f1_score(y_true, y_pred):.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}